action: "train_and_save" # train or test
name: ??? # name of the experiment needed for the logs
modality: ["RGB"] # modality used

total_batch: 128 # total batch size if training is done with gradient accumulation
batch_size: 32 # batch size for the forward

gpus: null # gpus adopted
wandb_name: "RGB-sEMG" # needed for wandb logging
resume_from: null # checkpoint directory
logname: null # name of the logs
models_dir: null # directory containing all the models
split: null

last_model: 
  encoder: "saved_models/VAE_RGB_EMG/VAE_RGB_EMG"
  decoder: "saved_models/VAE_RGB_EMG/VAE_RGB_EMG"

train:
  num_iter: 200 # number of training iterations with total_batch size
  lr_steps: 50 # steps before reducing learning rate
  eval_freq: 50 # evaluation frequency
  num_clips: 10 # clips adopted in training
  EMG:
    feature_size: 1664
  RGB:
    feature_size: 1024
  bottleneck_size: 256

save: 
  num_clips: 5 # clips adopted in save

test:
  num_clips: 5 # number of clips in testing


dataset:
  annotations_path: train_val
  shift: D1-D1
  workers: 4
  stride: 2
  num_classes: 20
  resolution: 224
  RGB:
    data_path: "../ek_data/frames"
    tmpl: "img_{:010d}.jpg"
    features_name: "10_dense_finetuned"
models:
  VAE:
    architecture:
      bottleneck: 256
    model: VariationalAutoencoder
    dropout: 0.2
    kwargs: {}
    epochs: 300
    lr_steps: 200
    lr: 0.01
    lr_gamma: 0.01
    beta: 0.0001